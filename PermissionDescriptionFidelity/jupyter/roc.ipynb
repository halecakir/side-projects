{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', '2')\n",
    "\n",
    "\n",
    "class ArgumentParser():\n",
    "    permission_type = \"READ_CONTACTS\"\n",
    "    train = \"/home/huseyinalecakir/Security/data/acnet-data/ACNET_DATASET.csv\"\n",
    "    train_file_type = \"acnet\"\n",
    "    test = \"/home/huseyinalecakir/Security/data/whyper/Read_Contacts.csv\"\n",
    "    test_file_type = \"whyper\"\n",
    "    external_embedding = \"/home/huseyinalecakir/Security/data/pretrained-embeddings/{}\".format(\"scraped_with_porter_stemming_300.bin\")\n",
    "    external_embedding_type = \"word2vec\"\n",
    "    wembedding_dims = 300\n",
    "    lstm_dims = 128\n",
    "    sequence_type = \"windowed\"\n",
    "    window_size = 2\n",
    "    stemmer = \"porter\"\n",
    "    lstm_type = \"lstm\"\n",
    "    saved_parameters_dir = \"/home/huseyinalecakir/Security/data/saved-parameters/\".format(wembedding_dims)\n",
    "    saved_prevectors = \"embeddings.pickle\"\n",
    "    saved_vocab_test = \"whyper-vocab.txt\"\n",
    "    saved_vocab_train = \"acnet-vocab.txt\"\n",
    "    saved_preprocessed_whyper = \"whyper-preprocessed.txt\"\n",
    "    saved_preprocessed_acnet = \"acnet-preprocessed.txt\"\n",
    "    outdir = \"./test/{}/{}/{}\".format(permission_type, lstm_type, wembedding_dims)\n",
    "    external_info = \"no_info\"\n",
    "    external_info_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import dynet as dy\n",
    "import dynet_config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from numpy import inf\n",
    "\n",
    "from utils.io_utils import IOUtils\n",
    "from utils.nlp_utils import NLPUtils\n",
    "\n",
    "# Declare GPU as the default device type\n",
    "dynet_config.set_gpu()\n",
    "# Set some parameters manualy\n",
    "dynet_config.set(mem=400, random_seed=123456789)\n",
    "# Initialize dynet import using above configuration in the current scope\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "\n",
    "class DocumentReport:\n",
    "    \"\"\"TODO\"\"\"\n",
    "    def __init__(self, app_id):\n",
    "        self.app_id = app_id\n",
    "        self.mark = False\n",
    "        self.preprocessed_sentences = []\n",
    "        self.sentences = []\n",
    "        self.prediction_result = None\n",
    "\n",
    "\n",
    "class SimilarityExperiment:\n",
    "    \"\"\"TODO\"\"\"\n",
    "    def __init__(self, w2i, options):\n",
    "        print('Similarity Experiment - init')\n",
    "        self.options = options\n",
    "        self.model = dy.ParameterCollection()\n",
    "        self.trainer = dy.SimpleSGDTrainer(self.model)\n",
    "        self.w2i = w2i\n",
    "        self.wdims = options.wembedding_dims\n",
    "        self.ldims = options.lstm_dims\n",
    "\n",
    "        self.ext_embeddings = None\n",
    "        #Model Parameters\n",
    "        self.wlookup = self.model.add_lookup_parameters((len(w2i), self.wdims))\n",
    "\n",
    "        self.__load_model()\n",
    "\n",
    "        if self.options.lstm_type == \"lstm\":\n",
    "            self.sentence_rnn = [dy.VanillaLSTMBuilder(2, self.wdims, self.ldims, self.model)]\n",
    "            self.document_rnn = [dy.VanillaLSTMBuilder(2, self.ldims, self.ldims, self.model)]\n",
    "            self.mlp_w = self.model.add_parameters((1, self.ldims))\n",
    "            self.mlp_b = self.model.add_parameters(1)\n",
    "\n",
    "        elif self.options.lstm_type == \"bilstm\":\n",
    "            self.sentence_rnn = [dy.VanillaLSTMBuilder(1, self.wdims, self.ldims, self.model),\n",
    "                                 dy.VanillaLSTMBuilder(1, self.wdims, self.ldims, self.model)]\n",
    "            self.document_rnn = [dy.VanillaLSTMBuilder(1, self.ldims, self.ldims, self.model),\n",
    "                                 dy.VanillaLSTMBuilder(1, self.ldims, self.ldims, self.model)]\n",
    "            self.mlp_w = self.model.add_parameters((1, 2*self.ldims))\n",
    "            self.mlp_b = self.model.add_parameters(1)\n",
    "        \n",
    "    def __load_model(self):\n",
    "        if self.options.external_embedding is not None:\n",
    "            if os.path.isfile(os.path.join(self.options.saved_parameters_dir,\n",
    "                                           self.options.saved_prevectors)):\n",
    "                self.__load_external_embeddings(os.path.join(self.options.saved_parameters_dir,\n",
    "                                                             self.options.saved_prevectors),\n",
    "                                                \"pickle\")\n",
    "            else:\n",
    "                self.__load_external_embeddings(self.options.external_embedding,\n",
    "                                                self.options.external_embedding_type)\n",
    "                self.__save_model()\n",
    "\n",
    "    def __save_model(self):\n",
    "        IOUtils.save_embeddings(os.path.join(self.options.saved_parameters_dir,\n",
    "                                             self.options.saved_prevectors),\n",
    "                                self.ext_embeddings)\n",
    "\n",
    "    def __load_external_embeddings(self, embedding_file, embedding_file_type):\n",
    "        ext_embeddings, ext_emb_dim = IOUtils.load_embeddings_file(\n",
    "            embedding_file,\n",
    "            embedding_file_type,\n",
    "            lower=True)\n",
    "        assert ext_emb_dim == self.wdims\n",
    "        self.ext_embeddings = {}\n",
    "        print(\"Initializing word embeddings by pre-trained vectors\")\n",
    "        count = 0\n",
    "        for word in self.w2i:\n",
    "            if word in ext_embeddings:\n",
    "                count += 1\n",
    "                self.ext_embeddings[word] = ext_embeddings[word]\n",
    "                self.wlookup.init_row(self.w2i[word], ext_embeddings[word])\n",
    "        print(\"Vocab size: %d; #words having pretrained vectors: %d\" % (len(self.w2i), count))\n",
    "\n",
    "\n",
    "def __load_row_acnet_file(infile, gold_permission, stemmer):\n",
    "    print(\"Loading row {} \".format(infile))\n",
    "    print(\"Reading Train Sentences\")\n",
    "    tagged_train_file = pd.read_csv(infile)\n",
    "    documents = []\n",
    "    acnet_map = {\"RECORD_AUDIO\" : \"MICROPHONE\", \"READ_CONTACTS\": \"CONTACTS\", \"READ_CALENDAR\": \"CALENDAR\", \"ACCESS_FINE_LOCATION\" : \"LOCATION\" ,\n",
    "    \"CAMERA\" : \"CAMERA\", \"READ_SMS\" : \"SMS\", \"READ_CALL_LOGS\" : \"CALL_LOG\", \"CALL_PHONE\" : \"PHONE\" , \"WRITE_SETTINGS\" : \"SETTINGS\" ,\n",
    "    \"GET_TASKS\" : \"TASKS\"}\\\n",
    "\n",
    "    for idx, row in tagged_train_file.iterrows():\n",
    "\n",
    "        app_id = int(row[\"app_id\"])\n",
    "        sentence = row[\"sentence\"]\n",
    "\n",
    "        if documents == []: #if it is the first document\n",
    "            documents.append(DocumentReport(app_id))\n",
    "        elif documents[-1].app_id != app_id: # if it is a new document\n",
    "            documents.append(DocumentReport(app_id))\n",
    "\n",
    "        if row[acnet_map[gold_permission]] is 1:\n",
    "            documents[-1].mark = True\n",
    "\n",
    "        documents[-1].sentences.append(sentence)\n",
    "        documents[-1].preprocessed_sentences.append(\" \".join(NLPUtils.preprocess_sentence(sentence, stemmer)))\n",
    "    print(\"Loading completed\")\n",
    "    return documents\n",
    "\n",
    "def __encode_sequence(model, seq, rnn_builder):\n",
    "    def predict_sequence(builder, inputs):\n",
    "        s_init = builder.initial_state()\n",
    "        return s_init.transduce(inputs)\n",
    "\n",
    "    if model.options.lstm_type == \"bilstm\":\n",
    "        f_in = [entry for entry in seq]\n",
    "        b_in = [rentry for rentry in reversed(seq)]\n",
    "        forward_sequence = predict_sequence(rnn_builder[0], f_in)\n",
    "        backward_sequence = predict_sequence(rnn_builder[1], b_in)\n",
    "        return dy.concatenate([forward_sequence[-1], backward_sequence[-1]])\n",
    "    elif model.options.lstm_type == \"lstm\":\n",
    "        f_in = [entry for entry in seq]\n",
    "        state = rnn_builder[0].initial_state()\n",
    "        for entry in seq:\n",
    "            state = state.add_input(entry)\n",
    "        return state.output()\n",
    "\n",
    "def __train(model, data):\n",
    "    total_loss = 0\n",
    "    for index, document in enumerate(data):\n",
    "        loss = None\n",
    "        sentence_encodings = []\n",
    "        for sentence in document.preprocessed_sentences:\n",
    "            seq = [model.wlookup[int(model.w2i.get(entry, 0))] for entry in sentence]\n",
    "            if len(seq) > 0:\n",
    "                encoded_phrase = __encode_sequence(model, seq, model.sentence_rnn)\n",
    "                sentence_encodings.append(encoded_phrase)\n",
    "\n",
    "        document_encoding = __encode_sequence(model, sentence_encodings, model.document_rnn)\n",
    "        y_pred = dy.logistic((model.mlp_w*document_encoding) + model.mlp_b)\n",
    "\n",
    "        if document.mark:\n",
    "            loss = dy.binary_log_loss(y_pred, dy.scalarInput(1))\n",
    "        else:\n",
    "            loss = dy.binary_log_loss(y_pred, dy.scalarInput(0))\n",
    "\n",
    "        total_loss += loss.scalar_value()\n",
    "        if index != 0 and index % 100 == 0:\n",
    "            print(\"Index {} Loss {}\".format(index, total_loss/(index+1)))\n",
    "        loss.backward()\n",
    "        model.trainer.update()\n",
    "        dy.renew_cg()\n",
    "\n",
    "def __predict(model, data):\n",
    "    for _, document in enumerate(data):\n",
    "        sentence_encodings = []\n",
    "        for sentence in document.preprocessed_sentences:\n",
    "            seq = [model.wlookup[int(model.w2i.get(entry, 0))] for entry in sentence]\n",
    "            if len(seq) > 0:\n",
    "                encoded_phrase = __encode_sequence(model, seq, model.sentence_rnn)\n",
    "                sentence_encodings.append(encoded_phrase)\n",
    "\n",
    "        document_encoding = __encode_sequence(model, sentence_encodings, model.document_rnn)\n",
    "        y_pred = dy.logistic((model.mlp_w*document_encoding) + model.mlp_b)\n",
    "        document.prediction_result = y_pred.scalar_value()\n",
    "        dy.renew_cg()\n",
    "\n",
    "\n",
    "def run(args):\n",
    "    print('Extracting training vocabulary')\n",
    "    w2i, _ = IOUtils.load_vocab(  args.train,\n",
    "                                        args.train_file_type,\n",
    "                                        args.saved_parameters_dir,\n",
    "                                        args.saved_vocab_train,\n",
    "                                        args.external_embedding,\n",
    "                                        args.external_embedding_type,\n",
    "                                        args.stemmer,\n",
    "                                        True)    \n",
    "\n",
    "    documents = __load_row_acnet_file(args.train,  args.permission_type, args.stemmer)\n",
    "    documents = np.array(documents)\n",
    "    random.shuffle(documents)\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    all_predictions = []\n",
    "    roc_scores = []\n",
    "    pr_scores = []\n",
    "    kfold = KFold(10, True, 1)\n",
    "    for foldid, (train, test) in enumerate(kfold.split(documents)):\n",
    "        model = SimilarityExperiment(w2i, args)\n",
    "        print(\"Fold {}:\".format(foldid))\n",
    "        print(\"Num. of train doc {}\".format(len(train)))\n",
    "        print(\"Num. of test doc {}\".format(len(test)))\n",
    "\n",
    "        test_documents = documents[test]\n",
    "        train_documents = documents[train]\n",
    "\n",
    "        __train(model, train_documents)\n",
    "        __predict(model, test_documents)\n",
    "\n",
    "        predictions = [r.prediction_result for r in test_documents]\n",
    "        gold = []\n",
    "        for r in test_documents:\n",
    "            if r.mark:\n",
    "                gold.append(1)\n",
    "            else:\n",
    "                gold.append(0)\n",
    "\n",
    "        y_true = np.array(gold)\n",
    "        y_scores = np.array(predictions)\n",
    "\n",
    "        roc_auc = roc_auc_score(y_true, y_scores)\n",
    "        pr_auc = average_precision_score(y_true, y_scores)\n",
    "\n",
    "        roc_scores.append(roc_auc)\n",
    "        pr_scores.append(pr_auc)\n",
    "\n",
    "        for r in test_documents:\n",
    "            mark = 1 if r.mark else 0\n",
    "            all_predictions.append([\" \".join(r.sentences), \" \".join(r.preprocessed_sentences), mark, r.prediction_result])\n",
    "\n",
    "    roc_pr_out_dir = os.path.join(model.options.outdir, \"roc_auc.txt\")\n",
    "    with open(roc_pr_out_dir, \"w\") as target:\n",
    "        target.write(\"ROC-AUC {}\\n\".format(sum(roc_scores)/len(roc_scores)))\n",
    "        target.write(\"PR-AUC {}\\n\".format(sum(pr_scores)/len(pr_scores)))\n",
    "\n",
    "    predictions_dir = os.path.join(model.options.outdir, \"predicted_file.txt\")\n",
    "    with open(predictions_dir, \"w\") as target:\n",
    "        for p in all_predictions:\n",
    "            target.write(\"{}\\n\".format(\"|||\".join(str(i) for i in p)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Extracting training vocabulary')\n",
    "w2i, _ = IOUtils.load_vocab(  args.train,\n",
    "                                    args.train_file_type,\n",
    "                                    args.saved_parameters_dir,\n",
    "                                    args.saved_vocab_train,\n",
    "                                    args.external_embedding,\n",
    "                                    args.external_embedding_type,\n",
    "                                    args.stemmer,\n",
    "                                    True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = __load_row_acnet_file(args.train,  args.permission_type, args.stemmer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = np.array(documents)\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(gold, predicted):\n",
    "    TP, TN, FN, FP = 0.0, 0.0, 0.0, 0.0\n",
    "    for g, p in zip(gold, predicted):\n",
    "        if g == 0:\n",
    "            if g == p:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        else:\n",
    "            if g == p:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    return TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_precision_recall(tp, tn, fp, fn):\n",
    "    precision = tp / (tp + fp)\n",
    "    recall  = tp / (tp + fn)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(gold, predicted):\n",
    "    print(gold, predicted)\n",
    "    tp, tn, fp, fn = confusion_matrix(gold, predicted)\n",
    "    accuracy, precision, recall = accuracy_precision_recall(tp, tn, fp, fn)\n",
    "    print(\"TP : {}\\nTN : {}\\nFP : {}\\nFN : {}\".format(tp, tn, fp, fn))\n",
    "    print(\"Accuracy : {}\\nPrecision : {}\\nRecall : {}\".format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "all_predictions = []\n",
    "roc_scores = []\n",
    "pr_scores = []\n",
    "kfold = KFold(10, True, 1)\n",
    "for foldid, (train, test) in enumerate(kfold.split(documents)):\n",
    "    model = SimilarityExperiment(w2i, args)\n",
    "    print(\"Fold {}:\".format(foldid))\n",
    "    print(\"Num. of train doc {}\".format(len(train)))\n",
    "    print(\"Num. of test doc {}\".format(len(test)))\n",
    "\n",
    "    test_documents = documents[test]\n",
    "    train_documents = documents[train]\n",
    "\n",
    "    __train(model, train_documents)\n",
    "    __predict(model, test_documents)\n",
    "\n",
    "    predictions = [r.prediction_result for r in test_documents]\n",
    "    gold = []\n",
    "    for r in test_documents:\n",
    "        if r.mark:\n",
    "            gold.append(1)\n",
    "        else:\n",
    "            gold.append(0)\n",
    "\n",
    "    y_true = np.array(gold)\n",
    "    y_scores = np.array(predictions)\n",
    "    \n",
    "\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true, y_scores)\n",
    "    pr_auc = average_precision_score(y_true, y_scores)\n",
    "\n",
    "    roc_scores.append(roc_auc)\n",
    "    pr_scores.append(pr_auc)\n",
    "    \n",
    "    show_metrics(gold, predictions)\n",
    "    print(\"AUC : {} PR-AUC : {}\".format(roc_auc, pr_auc))\n",
    "    for r in test_documents:\n",
    "        mark = 1 if r.mark else 0\n",
    "        all_predictions.append([\" \".join(r.sentences), \" \".join(r.preprocessed_sentences), mark, r.prediction_result])\n",
    "\n",
    "roc_pr_out_dir = os.path.join(model.options.outdir, \"roc_auc.txt\")\n",
    "with open(roc_pr_out_dir, \"w\") as target:\n",
    "    target.write(\"ROC-AUC {}\\n\".format(sum(roc_scores)/len(roc_scores)))\n",
    "    target.write(\"PR-AUC {}\\n\".format(sum(pr_scores)/len(pr_scores)))\n",
    "\n",
    "predictions_dir = os.path.join(model.options.outdir, \"predicted_file.txt\")\n",
    "with open(predictions_dir, \"w\") as target:\n",
    "    for p in all_predictions:\n",
    "        target.write(\"{}\\n\".format(\"|||\".join(str(i) for i in p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_pr_out_dir = os.path.join(model.options.outdir, \"roc_auc.txt\")\n",
    "with open(roc_pr_out_dir, \"w\") as target:\n",
    "    target.write(\"ROC-AUC {}\\n\".format(sum(roc_scores)/len(roc_scores)))\n",
    "    target.write(\"PR-AUC {}\\n\".format(sum(pr_scores)/len(pr_scores)))\n",
    "\n",
    "predictions_dir = os.path.join(model.options.outdir, \"predicted_file.txt\")\n",
    "with open(predictions_dir, \"w\") as target:\n",
    "    for p in all_predictions:\n",
    "        target.write(\"{}\\n\".format(\"|||\".join(str(i) for i in p)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
