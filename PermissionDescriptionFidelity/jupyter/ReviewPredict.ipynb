{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch import optim\n",
    "\n",
    "from utils.io_utils import IOUtils\n",
    "from utils.nlp_utils import NLPUtils\n",
    "from common import *\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "seed = 10\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgumentParser:\n",
    "    permission_type = \"READ_CONTACTS\"\n",
    "    train = \"/home/huseyinalecakir/Security/data/acnet-data/ACNET_DATASET.csv\"\n",
    "    train_file_type = \"acnet\"\n",
    "    external_embedding = \"/home/huseyinalecakir/Security/data/pretrained-embeddings/{}\".format(\"scraped_with_porter_stemming_300.bin\")\n",
    "    external_embedding_type = \"word2vec\"\n",
    "    stemmer = \"porter\"\n",
    "    saved_parameters_dir = \"/home/huseyinalecakir/Security/data/saved-parameters/\"\n",
    "    saved_prevectors    = \"embeddings.pickle\"\n",
    "    saved_vocab_train = \"acnet-vocab.txt\"\n",
    "    saved_all_data = \"{}/all_data\".format(saved_parameters_dir)\n",
    "    reviews = \"/home/huseyinalecakir/Security/data/reviews/acnet-reviews/acnet_initial/app_reviews_original.csv\"\n",
    "    lower = True\n",
    "    outdir = \"./test/{}\".format(permission_type)\n",
    "\n",
    "class TorchOptions:\n",
    "    rnn_size = 300\n",
    "    init_weight = 0.08\n",
    "    decay_rate = 0.985\n",
    "    learning_rate = 0.0001\n",
    "    plot_every = 2500\n",
    "    print_every = 2500\n",
    "    grad_clip = 5\n",
    "    dropout = 0\n",
    "    dropoutrec = 0\n",
    "    learning_rate_decay = 0.985\n",
    "    learning_rate_decay_after = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#ext_embeddings = load_embeddings(args)\n",
    "#reviews = load_reviews(args.reviews, args.stemmer, ext_embeddings)\n",
    "#sentences = load_row_acnet(args.train, args.stemmer, ext_embeddings)\n",
    "\"\"\"\n",
    "print('Extracting training vocabulary')\n",
    "w2i = IOUtils.load_vocab(args.train, \n",
    "                         args.train_file_type, \n",
    "                         args.saved_parameters_dir, \n",
    "                         args.saved_vocab_train,\n",
    "                         args.external_embedding,\n",
    "                         args.external_embedding_type,\n",
    "                         args.stemmer,\n",
    "                         args.lower)\n",
    "\n",
    "#Update review vocab\n",
    "review_vocab = reviews_vocab(reviews)\n",
    "for w in review_vocab:\n",
    "    if w not in w2i:\n",
    "        w2i[w] = len(w2i)\n",
    "\"\"\"\n",
    "#create_index_tensors(sentences, reviews, w2i)\n",
    "#save_all_data(args.saved_all_data, ext_embeddings, rev2, sentences, w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_item(opt, args, sentence, encoder, classifier, optimizer, criterion):\n",
    "    optimizer.zero_grad()\n",
    "    c = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    h = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    for i in range(sentence.index_tensor.size(1)):\n",
    "        c, h = encoder(sentence.index_tensor[:, i], c, h)\n",
    "\n",
    "    pred = classifier(h)\n",
    "    loss = criterion(pred, torch.tensor([[sentence.permissions[args.permission_type]]], dtype=torch.float))\n",
    "    loss.backward()\n",
    "    if opt.grad_clip != -1:\n",
    "        torch.nn.utils.clip_grad_value_(encoder.parameters(),opt.grad_clip)\n",
    "        torch.nn.utils.clip_grad_value_(classifier.parameters(),opt.grad_clip)\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def predict(opt, sentence, encoder, classifier):\n",
    "    c = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "    h = torch.zeros((1, opt.rnn_size), dtype=torch.float, requires_grad=True)\n",
    "\n",
    "    for i in range(sentence.index_tensor.size(1)):\n",
    "        c, h = encoder(sentence.index_tensor[:, i], c, h)\n",
    "    pred = classifier(h)\n",
    "    return pred\n",
    "\n",
    "def train_and_test(opt, args, epoch_num, w2i, train_data, test_data, foldid):\n",
    "    encoder = Encoder(opt, w2i, ext_embeddings)\n",
    "    classifier = Classifier(opt, 1) \n",
    "    \n",
    "    params = list(encoder.parameters()) + list(classifier.parameters())\n",
    "    optimizer = optim.Adam(params) \n",
    "    optim_state = {\"learningRate\" : opt.learning_rate, \"alpha\" :  opt.decay_rate}\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    pr_scores = []\n",
    "    roc_scores = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        print(\"---Epoch {}---\\n\".format(epoch+1))\n",
    "        \n",
    "        print(\"Training...\")\n",
    "        encoder.train()\n",
    "        classifier.train()\n",
    "        for index, sentence in enumerate(train_data):\n",
    "            loss = train_item(opt, args, sentence, encoder, classifier, optimizer, criterion)\n",
    "            if index != 0:\n",
    "                if index % opt.print_every == 0:\n",
    "                    print(\"Index {} Loss {}\".format(index,np.mean(losses[epoch*len(train_data)+index-opt.print_every:])))\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        # Learning Rate Decay Optimization\n",
    "        if opt.learning_rate_decay < 1:\n",
    "            if epoch >= opt.learning_rate_decay_after:\n",
    "                decay_factor = opt.learning_rate_decay\n",
    "                optim_state[\"learningRate\"] = optim_state[\"learningRate\"] * decay_factor \n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = optim_state[\"learningRate\"]\n",
    "\n",
    "        \n",
    "        print(\"Predicting..\")     \n",
    "        encoder.eval()\n",
    "        classifier.eval()\n",
    "        predictions = []\n",
    "        gold = []\n",
    "        with torch.no_grad():\n",
    "            for index, sentence in enumerate(test_data):\n",
    "                pred = predict(opt, sentence, encoder, classifier)\n",
    "                predictions.append(pred)\n",
    "                gold.append(sentence.permissions[args.permission_type])\n",
    "\n",
    "        y_true = np.array(gold)\n",
    "        y_scores = np.array(predictions)\n",
    "        roc_auc = roc_auc_score(y_true, y_scores)\n",
    "        pr_auc = average_precision_score(y_true, y_scores)\n",
    "        pr_scores.append(pr_auc)\n",
    "        roc_scores.append(roc_auc)\n",
    "        print(\"Scores ROC {} PR {}\".format(roc_auc, pr_auc))\n",
    "        \n",
    "        #Save Model\n",
    "        model_save_dir = os.path.join(args.saved_parameters_dir, \"models\", \"model_for_review_prediction.pt\")\n",
    "        if not os.path.exists(os.path.dirname(model_save_dir)):\n",
    "            os.makedirs(os.path.dirname(model_save_dir))\n",
    "        torch.save({\n",
    "            'encoder': encoder.state_dict(),\n",
    "            'classifier': classifier.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch' : epoch,\n",
    "            'loss' : loss,\n",
    "            'foldid' : foldid,\n",
    "            'pr_auc' : pr_auc,\n",
    "            'roc_auc' : roc_auc\n",
    "            }, model_save_dir)\n",
    "    return roc_scores, pr_scores\n",
    "\n",
    "def load_model_and_predict_reviews(args, model_path, reviews):\n",
    "    encoder = Encoder(opt, w2i, ext_embeddings)\n",
    "    classifier = Classifier(opt, 1) \n",
    "    \n",
    "    checkpoint = torch.load(model_path)\n",
    "    encoder.load_state_dict(checkpoint[\"encoder\"])\n",
    "    classifier.load_state_dict(checkpoint[\"classifier\"])\n",
    "\n",
    "    pr_auc = checkpoint[\"pr_auc\"]\n",
    "    roc_auc = checkpoint[\"roc_auc\"]\n",
    "    print(pr_auc, roc_auc)\n",
    "    with torch.no_grad():\n",
    "        for app_id in reviews:\n",
    "            for review in reviews[app_id]:\n",
    "                pred = predict(opt, review, encoder, classifier)\n",
    "                review.prediction_result = pred\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ArgumentParser()\n",
    "opt = TorchOptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(args.saved_all_data, \"without_prediction.pickle\")\n",
    "ext_embeddings, reviews, sentences, w2i = load_all_data(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = np.array(sentences)\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test(opt, args, 1, w2i, documents[:100], documents[:100], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(reviews.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = os.path.join(args.saved_parameters_dir, \"models\", \"model_for_review_prediction.pt\")\n",
    "load_model_and_predict_reviews(args, model_save_dir, nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(args.saved_all_data, \"with_prediction.pickle\")\n",
    "save_all_data(save_dir, ext_embeddings, nr, sentences, w2i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
