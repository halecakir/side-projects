{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch import optim\n",
    "\n",
    "from utils.io_utils import IOUtils\n",
    "from utils.nlp_utils import NLPUtils\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "seed = 10\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "class ArgumentParser:\n",
    "    permission_type = \"RECORD_AUDIO\"\n",
    "    saved_data = \"/home/huseyinalecakir/Security/data/saved-parameters/saved-data/emdeddings-sentences-w2i.pickle\"\n",
    "    saved_predicted_reviews = \"/home/huseyinalecakir/Security/data/saved-parameters/saved-data/predicted-RECORD_AUDIO-reviews.pickle\"\n",
    "    useful_reviews = 5\n",
    "    outdir = \"output.out\"\n",
    "\n",
    "class SentenceReport:\n",
    "    def __init__(self, id, sentence):\n",
    "        self.app_id = id\n",
    "        self.sentence = sentence\n",
    "        self.permissions = {}\n",
    "        self.preprocessed_sentence = None\n",
    "        self.prediction_result = None\n",
    "        self.index_tensor = None\n",
    "\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, sentence, score):\n",
    "        self.sentence = sentence\n",
    "        self.preprocessed_sentence = None\n",
    "        self.score = score\n",
    "        self.index_tensor = None\n",
    "        self.prediction_result = None\n",
    "\n",
    "class TorchOptions:\n",
    "    hidden_size = 300\n",
    "    init_weight = 0.08\n",
    "    output_size = 1\n",
    "    print_every = 1000\n",
    "    grad_clip = 5\n",
    "    dropout = 0\n",
    "    dropoutrec = 0\n",
    "    learning_rate_decay = 1  # 0.985\n",
    "    learning_rate_decay_after = 1\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.w2i = None\n",
    "        self.entries = None\n",
    "        self.train_entries = None\n",
    "        self.test_entries = None\n",
    "        self.ext_embedding = None\n",
    "        self.predicted_reviews = None\n",
    "            \n",
    "    def load(self, infile):\n",
    "        with open(infile, \"rb\") as target:\n",
    "            self.ext_embeddings, self.entries, self.w2i = pickle.load(target)\n",
    "            \n",
    "    def load_predicted_reviews(self, infile):\n",
    "        with open(infile, \"rb\") as target:\n",
    "            self.predicted_reviews = pickle.load(target)\n",
    "        for app_id in self.predicted_reviews.keys():\n",
    "            self.predicted_reviews[app_id].sort(key=lambda x: x.prediction_result.item(), reverse=True)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, opt, w2i):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.w2i = w2i\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.opt.hidden_size, self.opt.hidden_size, batch_first=True\n",
    "        )\n",
    "        if opt.dropout > 0:\n",
    "            self.dropout = nn.Dropout(opt.dropout)\n",
    "        self.embedding = nn.Embedding(len(self.w2i), self.opt.hidden_size)\n",
    "        self.__initParameters()\n",
    "\n",
    "    def __initParameters(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                init.uniform_(param, -self.opt.init_weight, self.opt.init_weight)\n",
    "\n",
    "    def initalizedPretrainedEmbeddings(self, embeddings):\n",
    "        weights_matrix = np.zeros(((len(self.w2i), self.opt.hidden_size)))\n",
    "        for word in self.w2i:\n",
    "            weights_matrix[self.w2i[word]] = embeddings[word]\n",
    "        self.embedding.weight = nn.Parameter(torch.FloatTensor(weights_matrix))\n",
    "\n",
    "    def forward(self, input_src):\n",
    "        src_emb = self.embedding(input_src)  # batch_size x src_length x emb_size\n",
    "        if self.opt.dropout > 0:\n",
    "            src_emb = self.dropout(src_emb)\n",
    "        outputs, (h, c) = self.lstm(src_emb)\n",
    "        return outputs, (h, c)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.hidden_size = opt.hidden_size\n",
    "        self.linear = nn.Linear(2*self.hidden_size, opt.output_size)\n",
    "\n",
    "        if opt.dropout > 0:\n",
    "            self.dropout = nn.Dropout(opt.dropout)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.__initParameters()\n",
    "\n",
    "    def __initParameters(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                init.uniform_(param, -self.opt.init_weight, self.opt.init_weight)\n",
    "\n",
    "    def forward(self, prev_h):\n",
    "        if self.opt.dropout > 0:\n",
    "            prev_h = self.dropout(prev_h)\n",
    "        h2y = self.linear(prev_h)\n",
    "        pred = self.sigmoid(h2y)\n",
    "        return pred\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.opt = None\n",
    "        self.encoders = {}\n",
    "        self.review_encoder = None\n",
    "        self.classifier = None\n",
    "        self.optimizer = None\n",
    "        self.criterion = None\n",
    "        \n",
    "    def create(self, opt, data):\n",
    "        self.opt = opt\n",
    "        self.encoders[\"sentence\"] = Encoder(self.opt, data.w2i)\n",
    "        self.encoders[\"reviewL1\"] = Encoder(self.opt, data.w2i)\n",
    "        self.encoders[\"reviewL2\"] =  nn.LSTMCell(opt.hidden_size, opt.hidden_size)\n",
    "        params = []\n",
    "        for encoder in self.encoders:\n",
    "            params += list(self.encoders[encoder].parameters())\n",
    "        self.classifier = Classifier(self.opt)\n",
    "        params += list(self.classifier.parameters())\n",
    "        self.optimizer = optim.Adam(params)\n",
    "        self.criterion = nn.BCELoss()\n",
    "    \n",
    "    def train(self):\n",
    "        for encoder in self.encoders:\n",
    "            self.encoders[encoder].train()\n",
    "        self.classifier.train()\n",
    "        \n",
    "    def eval(self):\n",
    "        for encoder in self.encoders:\n",
    "            self.encoders[encoder].eval()\n",
    "        self.classifier.eval()\n",
    "\n",
    "    def step(self):\n",
    "        self.optimizer.step()\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def grad_clip(self):\n",
    "        for encoder in self.encoders:\n",
    "            torch.nn.utils.clip_grad_value_(self.encoders[encoder].parameters(), self.opt.grad_clip)\n",
    "            self.encoders[encoder].train()\n",
    "        torch.nn.utils.clip_grad_value_(self.classifier.parameters(), self.opt.grad_clip)\n",
    "            \n",
    "    def save(self, filename):\n",
    "        checkpoint = {}\n",
    "        checkpoint[\"opt\"] = self.opt\n",
    "        for encoder in self.encoders:\n",
    "            checkpoint[encoder] = self.encoders[encoder].state_dict()\n",
    "        checkpoint[\"classifier\"] = self.classifier.state_dict()\n",
    "        checkpoint[\"optimizer\"] = self.optimizer.state_dict()\n",
    "        torch.save(checkpoint, filename)\n",
    "    \n",
    "    def load(self, filename, data):\n",
    "        checkpoint = torch.load(filename)\n",
    "        opt = checkpoint[\"opt\"]\n",
    "        self.create(opt, data)\n",
    "        for encoder in self.encoders:\n",
    "            self.encoders[encoder].load_state_dict(checkpoint[encoder])\n",
    "        self.decoder.load_state_dict(checkpoint[\"classifier\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "def write_file(filename, string):\n",
    "    with open(filename, \"a\") as target:\n",
    "        target.write(\"{}\\n\".format(string))\n",
    "        target.flush()\n",
    "\n",
    "def train_item(args, model, sentence, reviews):\n",
    "    model.zero_grad()\n",
    "    outputs_s, (hidden_s, cell_s) = model.encoders[\"sentence\"](sentence.index_tensor)\n",
    "    \n",
    "    hidden_r_lst = []\n",
    "    for review in reviews:\n",
    "        outputs_r, (hidden_r, cell_r) = model.encoders[\"reviewL1\"](review.index_tensor)\n",
    "        hidden_r_lst.append(hidden_r)\n",
    "        \n",
    "    hidden_rl2, cell_rl2 = None, None\n",
    "    for hidden_r in hidden_r_lst:\n",
    "        hidden_rl2, cell_rl2 = model.encoders[\"reviewL2\"](hidden_r.view(1,-1))\n",
    "\n",
    "    hidden = torch.cat((hidden_s, hidden_rl2.view(1, 1,-1)), 2)\n",
    "    pred = model.classifier(hidden)\n",
    "    loss = model.criterion(\n",
    "        pred,\n",
    "        torch.tensor(\n",
    "            [[[sentence.permissions[args.permission_type]]]], dtype=torch.float\n",
    "        ),\n",
    "    )\n",
    "    loss.backward()\n",
    "\n",
    "    if model.opt.grad_clip != -1:\n",
    "        model.grad_clip()\n",
    "    model.step()\n",
    "    return loss\n",
    "\n",
    "def test_item(model, sentence, reviews):\n",
    "    outputs_s, (hidden_s, cell_s) = model.encoders[\"sentence\"](sentence.index_tensor)\n",
    "    \n",
    "    hidden_r_lst = []\n",
    "    for review in reviews:\n",
    "        outputs_r, (hidden_r, cell_r) = model.encoders[\"reviewL1\"](review.index_tensor)\n",
    "        hidden_r_lst.append(hidden_r)\n",
    "        \n",
    "    hidden_rl2, cell_rl2 = None, None\n",
    "    for hidden_r in hidden_r_lst:\n",
    "        hidden_rl2, cell_rl2 = model.encoders[\"reviewL2\"](hidden_r.view(1,-1))\n",
    "\n",
    "    hidden = torch.cat((hidden_s, hidden_rl2.view(1, 1,-1)), 2)\n",
    "    pred = model.classifier(hidden)\n",
    "    return pred\n",
    "\n",
    "def train_all(args, model, data):\n",
    "    write_file(args.outdir, \"Training...\")\n",
    "    \n",
    "    model.train()\n",
    "    losses = []\n",
    "    for index, sentence in enumerate(data.train_entries):\n",
    "        if sentence.app_id in data.predicted_reviews:\n",
    "            loss = train_item(args, model, sentence, data.predicted_reviews[sentence.app_id][:args.useful_reviews])\n",
    "        if index != 0:\n",
    "            if index % model.opt.print_every == 0:\n",
    "                write_file(args.outdir,\n",
    "                    \"Index {} Loss {}\".format(\n",
    "                        index, np.mean(losses[index - model.opt.print_every :])\n",
    "                    )\n",
    "                )\n",
    "        losses.append(loss.item())\n",
    "\n",
    "\n",
    "def test_all(args, model, data):\n",
    "    def pr_roc_auc(predictions, gold):\n",
    "        y_true = np.array(gold)\n",
    "        y_scores = np.array(predictions)\n",
    "        roc_auc = roc_auc_score(y_true, y_scores)\n",
    "        pr_auc = average_precision_score(y_true, y_scores)\n",
    "        return roc_auc, pr_auc\n",
    "    \n",
    "    write_file(args.outdir, \"Predicting..\")\n",
    "    \n",
    "    predictions, gold = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for index, sentence in enumerate(data.test_entries):\n",
    "            if sentence.app_id in data.predicted_reviews:\n",
    "                pred = test_item(model, sentence, data.predicted_reviews[sentence.app_id][:args.useful_reviews])\n",
    "                predictions.append(pred)\n",
    "                gold.append(sentence.permissions[args.permission_type])\n",
    "    return pr_roc_auc(predictions, gold)\n",
    "\n",
    "def kfold_validation(args, opt, data):\n",
    "    data.entries = np.array(data.entries)\n",
    "    random.shuffle(data.entries)\n",
    "\n",
    "    kfold = KFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "    roc_l, pr_l = [], []\n",
    "    for foldid, (train, test) in enumerate(kfold.split(data.entries)):\n",
    "        write_file(args.outdir, \"Fold {}\".format(foldid+1))\n",
    "        \n",
    "        model = Model()\n",
    "        model.create(opt, data)\n",
    "        data.train_entries = data.entries[train]\n",
    "        data.test_entries = data.entries[test]\n",
    "                                         \n",
    "        train_all(args, model, data)\n",
    "        roc_auc, pr_auc = test_all(args, model, data)\n",
    "        \n",
    "        write_file(args.outdir, \"ROC {} PR {}\".format(roc_auc, pr_auc))\n",
    "        roc_l.append(roc_auc)\n",
    "        pr_l.append(pr_auc)\n",
    "    write_file(args.outdir, \"Summary : ROC {} PR {}\".format(np.mean(roc_l), np.mean(pr_l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ArgumentParser()\n",
    "opt = TorchOptions()\n",
    "\n",
    "data = Data()\n",
    "data.load(args.saved_data)\n",
    "data.load_predicted_reviews(args.saved_predicted_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f9b9c936218f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkfold_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-cb854e5ac76d>\u001b[0m in \u001b[0;36mkfold_validation\u001b[0;34m(args, opt, data)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_entries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mroc_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-9382b90b52c0>\u001b[0m in \u001b[0;36mtrain_all\u001b[0;34m(args, model, data)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_reviews\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0museful_reviews\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-4d41928f0ccc>\u001b[0m in \u001b[0;36mtrain_item\u001b[0;34m(args, model, sentence, reviews)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_clip\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-8c9471f54cc5>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold_validation(args, opt, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
